import streamlit as st
import requests
import json

# --- NASTAVENÃ STRÃNKY ---
st.set_page_config(
    page_title="AAT v0.3.4",
    page_icon="ğŸš—",
    layout="wide"
)

# Sidebar s verzÃ­
st.sidebar.title("AAT OvlÃ¡dÃ¡nÃ­")
st.sidebar.info("Nasazena verze: 0.3.4")
st.sidebar.write("ğŸ§  **Model:** Llama 3.1 (8B)")
st.sidebar.write("âš¡ **ReÅ¾im:** Streaming")

# --- FUNKCE PRO OLLAMU SE STREAMINGEM ---
def get_ollama_response(user_input):
    url = "http://127.0.0.1:11434/api/generate"
    payload = {
        "model": "llama3.1:8b",
        "prompt": user_input,
        "stream": True  # Povolujeme streaming na stranÄ› Ollamy
    }
    
    full_response = ""
    # VytvoÅ™Ã­me prÃ¡zdnÃ½ box v UI, do kterÃ©ho budeme sypat text
    message_placeholder = st.empty()
    
    try:
        # NastavÃ­me stream=True i pro HTTP poÅ¾adavek
        with requests.post(url, json=payload, timeout=300, stream=True) as response:
            response.raise_for_status()
            
            for line in response.iter_lines():
                if line:
                    # DekÃ³dujeme Å™Ã¡dek z JSONu
                    chunk = json.loads(line.decode('utf-8'))
                    token = chunk.get("response", "")
                    full_response += token
                    
                    # OkamÅ¾itÄ› aktualizujeme UI (pÅ™idÃ¡me kurzor pro efekt)
                    message_placeholder.markdown(full_response + "â–Œ")
                    
                    if chunk.get("done"):
                        break
        
        # Po skonÄenÃ­ vypÃ­Å¡eme finÃ¡lnÃ­ text bez kurzoru
        message_placeholder.markdown(full_response)
        return full_response

    except Exception as e:
        error_msg = f"âŒ Chyba komunikace: {str(e)}"
        st.error(error_msg)
        return error_msg

# --- HLAVNÃ NAVIGACE ---
tabs = st.tabs([
    "ğŸ“Š Dashboard", 
    "ğŸ“‘ Requirements", 
    "ğŸ”— Traceability", 
    "ğŸ” Code Review", 
    "ğŸ’¬ Chat s Ollamou"
])

# 1. TAB: DASHBOARD
with tabs[0]:
    st.title("Automotive Assistance Tool (AAT) v0.3.4")
    col1, col2 = st.columns(2)
    with col1:
        st.header("SystÃ©movÃ½ pÅ™ehled")
        st.write("VÃ­tejte v AAT. AI asistent je nynÃ­ pÅ™ipojen v reÅ¾imu streamovÃ¡nÃ­.")
        st.success("âœ… Provoz: Docker (Host Network)")
    with col2:
        st.header("Statistiky")
        st.metric(label="Dostupnost AI", value="Online (Streaming)")

# 2. - 4. TAB: (ZatÃ­m prÃ¡zdnÃ©)
with tabs[1]: st.header("Requirements (DNG)")
with tabs[2]: st.header("Traceability Matrix")
with tabs[3]: st.header("Code Review")

# 5. TAB: CHAT (AI ASISTENT)
with tabs[4]:
    st.header("ğŸ’¬ AI Asistent (Ollama)")
    
    # Inicializace historie zprÃ¡v
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ZobrazenÃ­ historie zprÃ¡v
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Vstup od uÅ¾ivatele
    if prompt := st.chat_input("Zeptej se na CAN bus, ISO 26262 nebo cokoliv..."):
        # UloÅ¾Ã­me dotaz do historie
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # GenerovÃ¡nÃ­ odpovÄ›di
        with st.chat_message("assistant"):
            # ZavolÃ¡me naÅ¡i streamovacÃ­ funkci
            full_ans = get_ollama_response(prompt)
            
        # UloÅ¾Ã­me hotovou odpovÄ›Ä do historie
        st.session_state.messages.append({"role": "assistant", "content": full_ans})