import streamlit as st
import requests
import json

# --- NASTAVENÃ STRÃNKY ---
st.set_page_config(
    page_title="AAT v0.3.1",
    page_icon="ğŸš—",
    layout="wide"
)

# Sidebar
st.sidebar.title("AAT OvlÃ¡dÃ¡nÃ­")
st.sidebar.info("Nasazena verze: 0.3.1")

# --- FUNKCE PRO OLLAMU ---
def get_ollama_response(user_input):
    # Definice URL musÃ­ bÃ½t UVNITÅ˜ funkce, aby ji Python vidÄ›l
    url = "http://host.docker.internal:11434/api/generate"
    
    payload = {
        "model": "llama3.1:8b",
        "prompt": user_input,
        "stream": False
    }
    
    try:
        response = requests.post(url, json=payload, timeout=45)
        if response.status_code == 200:
            return response.json().get("response", "Chyba: PrÃ¡zdnÃ¡ odpovÄ›Ä.")
        else:
            return f"âš ï¸ Chyba serveru Ollama: KÃ³d {response.status_code}"
    except Exception as e:
        # Pokud se nÄ›co pokazÃ­, vypÃ­Å¡eme pÅ™esnou chybu
        return f"â“ Chyba komunikace: {str(e)}"

# --- HLAVNÃ NAVIGACE (TABY) ---
tabs = st.tabs(["ğŸ“Š Dashboard", "ğŸ“‘ Requirements", "ğŸ”— Traceability", "ğŸ” Code Review", "ğŸ’¬ Chat s Ollamou"])

# 1. TAB: DASHBOARD
with tabs[0]:
    st.title("Automotive Assistance Tool (AAT) v0.3.1")
    st.header("SystÃ©movÃ½ pÅ™ehled")
    st.success("âœ… Aplikace bÄ›Å¾Ã­ v Dockeru")

# ... (ostatnÃ­ taby 1, 2, 3 nechej prÃ¡zdnÃ© nebo jak jsi mÄ›l) ...

# 5. TAB: CHAT
with tabs[4]:
    st.header("ğŸ’¬ AI Asistent (Ollama)")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Zeptej se na nÄ›co..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Ollama pÅ™emÃ½Å¡lÃ­..."):
                full_response = get_ollama_response(prompt)
                st.markdown(full_response)
        
        st.session_state.messages.append({"role": "assistant", "content": full_response})